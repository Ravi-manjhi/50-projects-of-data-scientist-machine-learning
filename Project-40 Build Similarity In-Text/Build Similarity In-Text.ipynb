{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":[],"mount_file_id":"1DOSbkEiV2Q2WGg59M8N2jOVjOUIRkh5-","authorship_tag":"ABX9TyOT8ISUwA2kBkN6C/waTuLe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# ! pip install neattext"],"metadata":{"id":"oPWcL2fTLcXl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CLebJVgSFTee"},"outputs":[],"source":["import re\n","import time\n","import nltk\n","import random\n","import requests\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import neattext.functions as nfx\n","from nltk.corpus import stopwords\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","source":["# nltk.download('stopwords')"],"metadata":{"id":"-FgCE5XmN0_W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Taking example thext sample\n","text = \"J. Walk @walk35_18h I read the article. He essentially said that instead of trying to fit a woman into the role, they should write an original character better the james bond for a woman.\"\n","text2 = \"Joe Lare- the star of the famus adventure movie 'Tarzen': The Epic Adventure has passed away in a plane crash. The 58-year-old was with his wife\""],"metadata":{"id":"I-7JVnhFKdau"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cleaning(text):\n","  def cleanHtml(raw_html):\n","    cleaner = re.compile('<.*?>')\n","    cleanText = re.sub(cleaner, '', raw_html)\n","    return cleanText\n","\n","  def replaceUrls(data):\n","    url_pattern = re.compile(r'https?;//\\S+|www\\.\\S+')\n","    data = url_pattern.sub(r'', data)\n","    return data\n","\n","  def removeEmail(data):\n","    email = re.sub('\\S*@\\S*\\s?', '', data) \n","    return email\n","\n","  def misc(data):\n","    data = re.sub(r'\\.+', \".\", data)\n","    data = re.sub('\\s+', \" \", data)\n","    data = re.sub(\"\\'\", '', data)\n","    return data\n","\n","  sentance = cleanHtml(text)\n","  sentance = replaceUrls(sentance)\n","  sentance = removeEmail(sentance)\n","  sentance = misc(sentance)\n","  sentance = re.sub(r'[^a-zA-Z]', ' ', sentance)\n","  sentance = re.sub(' +', ' ', sentance)\n","  \n","  return sentance.lower()"],"metadata":{"id":"Az0dXbiaNGbd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["stopword_list = set(stopwords.words('english'))"],"metadata":{"id":"9TCAC0RON0tn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def removeStopwords(text):\n","  words = text.split()\n","  filterd_words = [word for word in words if word not in stopword_list]\n","  return ' '.join(filterd_words)"],"metadata":{"id":"KxtpK8k0Q1ql"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["removeStopwords(cleaning(text))"],"metadata":{"id":"WLbpcc_BRXvr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/Data Science/Project-40 Build Similarity In-Text/word_embeddings_smaller.pickle\"\n","with open(path, 'rb') as save_data:\n","  word_embed = pickle.load(save_data)"],"metadata":{"id":"slufin_bTDL_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creating metrics\n","document_embeddings = np.zeros(50, dtype='float')\n","count = 0\n","\n","try:\n","  for i in removeStopwords(cleaning(text)).split(' '):\n","    array = np.asarray(word_embed[i], dtype='float')\n","    document_embeddings = np.add(document_embeddings, array, out=document_embeddings, casting='unsafe')\n","except:\n","  count += 1\n","\n","\n","print(\"Number of words in text 1\", len(removeStopwords(cleaning(text)).split(' ')))\n","print(\"Unrecognizabe word count in text 1:\", count)\n"],"metadata":{"id":"16xuk81eVdlB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creating metrics\n","document_embeddings_2 = np.zeros(50, dtype='float')\n","count_2 = 0\n","\n","try:\n","  for i in removeStopwords(cleaning(text2)).split(' '):\n","    array = np.asarray(word_embed[i], dtype='float')\n","    document_embeddings_2 = np.add(document_embeddings_2, array, out=document_embeddings_2, casting='unsafe')\n","except:\n","  count_2 += 1\n","print(\"Number of words in text 1\", len(removeStopwords(cleaning(text2)).split(' ')))\n","print(\"Unrecognizabe word count in text 1:\", count_2)\n"],"metadata":{"id":"iQOD04ugaZpI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["document_embeddings"],"metadata":{"id":"zBspHFgnY74w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["document_embeddings_2"],"metadata":{"id":"EH7sedufarP_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# building cosine_similarity\n","\n","def cosine_similarity(A, B):\n","\n","  dot = np.dot(A, B)\n","  norma = np.sqrt(np.dot(A, A))\n","  normb = np.sqrt(np.dot(B, B))\n","  cos = dot / (norma * normb)\n","  return cos"],"metadata":{"id":"KPvBm_v_ata3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cosine_similarity(document_embeddings, document_embeddings_2)"],"metadata":{"id":"agEo2tULbP26"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"j5bOhePebUHv"},"execution_count":null,"outputs":[]}]}